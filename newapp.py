import streamlit as st
import google.generativeai as genai
import yt_dlp
import os
import json
import tempfile
import time
import subprocess
import re
import shutil
from pathlib import Path
from datetime import datetime

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê¸°ë³¸ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_FFMPEG_FALLBACK = r"C:\Users\Administrator\AppData\Local\Microsoft\WinGet\Packages\Gyan.FFmpeg_Microsoft.Winget.Source_8wekyb3d8bbwe\ffmpeg-8.0.1-full_build\bin"
FFMPEG_PATH = shutil.which("ffmpeg") or os.path.join(_FFMPEG_FALLBACK, "ffmpeg.exe")
FFPROBE_PATH = shutil.which("ffprobe") or os.path.join(_FFMPEG_FALLBACK, "ffprobe.exe")

DEFAULT_OUTPUT_DIR = Path(__file__).parent / "output"
DEFAULT_OUTPUT_DIR.mkdir(exist_ok=True)

AVAILABLE_MODELS = {
    "gemini-2.5-flash": "Gemini 2.5 Flash â€” ì•ˆì •ì , ë¬´ë£Œ í‹°ì–´",
    "gemini-2.5-flash-lite": "Gemini 2.5 Flash Lite â€” ê°€ì¥ ì €ë ´",
    "gemini-2.5-pro": "Gemini 2.5 Pro â€” ê³ ì„±ëŠ¥",
    "gemini-2.0-flash": "Gemini 2.0 Flash â€” ë ˆê±°ì‹œ (2026.3 ì¢…ë£Œ)",
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í˜ì´ì§€ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="ì˜ìƒ í¸ì§‘ ë¶„ì„ê¸°", page_icon="ğŸ¬", layout="wide")
st.title("ğŸ¬ ì˜ìƒ í¸ì§‘ ë¶„ì„ê¸°")
st.markdown("YouTube ì˜ìƒì˜ í¸ì§‘ íŒ¨í„´ì„ AIë¡œ ë¶„ì„í•˜ê³ , ìŠ¤í† ë¦¬ë³´ë“œ ìƒì„±ìš© í•™ìŠµ ë°ì´í„°ë¥¼ ë§Œë“­ë‹ˆë‹¤.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‚¬ì´ë“œë°”
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")

    api_key = st.text_input(
        "Google Gemini API Key",
        type="password",
        help="Google AI Studioì—ì„œ ë°œê¸‰ë°›ì€ í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.",
    )
    if api_key:
        os.environ["GOOGLE_API_KEY"] = api_key
        genai.configure(api_key=api_key)
        st.success("API í‚¤ ì„¤ì • ì™„ë£Œ")

    st.divider()

    selected_model = st.selectbox(
        "Gemini ëª¨ë¸",
        options=list(AVAILABLE_MODELS.keys()),
        format_func=lambda x: AVAILABLE_MODELS[x],
        index=0,
        help="ì˜ìƒ ë¶„ì„ì— ì‚¬ìš©í•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”.",
    )

    st.divider()

    use_scene_detection = st.checkbox(
        "FFmpeg ì”¬ ì²´ì¸ì§€ ê°ì§€ ì‚¬ìš©",
        value=True,
        help="FFmpegë¡œ í¸ì§‘ì ì„ ë¨¼ì € ì¶”ì¶œí•œ ë’¤ Geminiì— ë„˜ê¹ë‹ˆë‹¤. ì •í™•ë„ê°€ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤.",
    )
    scene_threshold = st.slider(
        "ì”¬ ì²´ì¸ì§€ ê°ë„",
        min_value=0.1,
        max_value=0.6,
        value=0.3,
        step=0.05,
        help="ë‚®ì„ìˆ˜ë¡ ë¯¼ê° (ì»· ë§ì´ ê²€ì¶œ), ë†’ì„ìˆ˜ë¡ í° ë³€í™”ë§Œ ê²€ì¶œ",
    )

    st.divider()

    output_format = st.radio("ì¶œë ¥ í˜•ì‹", ["JSON", "Markdown"], index=0)

    st.divider()

    auto_save = st.checkbox("ë¶„ì„ ê²°ê³¼ ìë™ ì €ì¥", value=True)
    save_dir = DEFAULT_OUTPUT_DIR
    if auto_save:
        save_path = st.text_input("ì €ì¥ ê²½ë¡œ", value=str(DEFAULT_OUTPUT_DIR))
        save_dir = Path(save_path)
        if not save_dir.exists():
            try:
                save_dir.mkdir(parents=True, exist_ok=True)
                st.success(f"í´ë” ìƒì„±ë¨: {save_dir}")
            except Exception as e:
                st.error(f"í´ë” ìƒì„± ì‹¤íŒ¨: {e}")
                save_dir = DEFAULT_OUTPUT_DIR

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í”„ë¡¬í”„íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# ì”¬ ì²´ì¸ì§€ ë°ì´í„° ì—†ì´ Geminië§Œ ì‚¬ìš©í•  ë•Œ
PROMPT_WITHOUT_SCENE_DATA = """\
# Role
You are a professional video editor analyzing a startup event sketch video.
Your analysis will be used as **training data** to let an LLM generate storyboards and timelines for future videos.

# Task
Watch the entire video and produce a structured JSON analysis.
Focus on **editorial intent** (why each cut was made) as much as technical attributes.

# Guidelines
- Timestamp to the nearest **1 second** (do NOT fabricate sub-second precision).
- Identify every distinct shot/cut you can observe.
- For each shot, classify both its technical attributes AND its editorial purpose.
- At the end, summarize the overall editing patterns so an LLM can replicate the style.

# Shot Types
Extreme Wide Shot | Wide Shot | Full Shot | Medium Shot | Medium Close-up | Close-up | Extreme Close-up | Over-the-Shoulder | POV Shot | Two Shot | Insert Shot | Cutaway

# Camera Movement
Static | Pan (Left/Right) | Tilt (Up/Down) | Zoom In | Zoom Out | Dolly In | Dolly Out | Tracking/Follow | Crane/Jib | Handheld | Steadicam

# Subject Types
speaker | audience | product_demo | venue_exterior | venue_interior | signage_branding | networking | B-roll | title_card | transition_graphic

# Editorial Purpose
establish_context | introduce_speaker | build_energy | deliver_information | show_reaction | emotional_beat | transition | pacing_break | closing

# Output JSON Schema
{
  "total_duration": "MM:SS",
  "scenes": [
    {
      "index": 1,
      "start": "MM:SS",
      "end": "MM:SS",
      "duration_sec": 3.0,
      "shot_type": "Medium Shot",
      "camera_movement": "Static",
      "subject_type": "speaker",
      "editorial_purpose": "introduce_speaker",
      "description": "ë°œí‘œìê°€ ë¬´ëŒ€ ì¤‘ì•™ì—ì„œ ì¸ì‚¬í•˜ë©° ë°œí‘œë¥¼ ì‹œì‘"
    }
  ],
  "editing_patterns": {
    "avg_cut_duration_sec": 2.5,
    "pacing_curve": "slow_start â†’ fast_middle â†’ slow_end",
    "shot_type_distribution": {
      "Wide Shot": 15,
      "Medium Shot": 40,
      "Close-up": 30,
      "Other": 15
    },
    "recurring_sequences": [
      "Wide â†’ Medium â†’ Close-up íŒ¨í„´ì´ ë°œí‘œ ì„¹ì…˜ì—ì„œ ë°˜ë³µ"
    ],
    "dominant_camera_style": "Static with occasional slow pan"
  },
  "narrative_structure": "ë„ì…(í–‰ì‚¬ì¥ ì „ê²½) â†’ ì „ê°œ(ë°œí‘œ í•˜ì´ë¼ì´íŠ¸) â†’ í´ë¼ì´ë§¥ìŠ¤(ê´€ê° ë°˜ì‘) â†’ ë§ˆë¬´ë¦¬(ë„¤íŠ¸ì›Œí‚¹)",
  "summary": "ì „ì²´ í¸ì§‘ ìŠ¤íƒ€ì¼ ìš”ì•½ (í†¤, ì†ë„ê°, íŠ¹ì§•ì  ê¸°ë²• ë“±)"
}

Return ONLY valid JSON. No markdown fences, no extra text.
"""

# ì”¬ ì²´ì¸ì§€ ë°ì´í„°ê°€ ìˆì„ ë•Œ (2ë‹¨ê³„ íŒŒì´í”„ë¼ì¸)
PROMPT_WITH_SCENE_DATA = """\
# Role
You are a professional video editor analyzing a startup event sketch video.
Your analysis will be used as **training data** to let an LLM generate storyboards and timelines for future videos.

# Pre-extracted Scene Change Data
FFmpeg has already detected the following cut points (timestamps in seconds):
{scene_timestamps}

Total detected cuts: {cut_count}

Use these timestamps as a **reliable guide** for where edits occur.
Your job is to watch the video and describe WHAT and WHY at each cut point.

# Task
For each segment between cut points, analyze:
1. Technical shot attributes (type, camera movement)
2. Editorial intent (why this cut exists)
3. Content description

Then summarize overall editing patterns.

# Shot Types
Extreme Wide Shot | Wide Shot | Full Shot | Medium Shot | Medium Close-up | Close-up | Extreme Close-up | Over-the-Shoulder | POV Shot | Two Shot | Insert Shot | Cutaway

# Camera Movement
Static | Pan (Left/Right) | Tilt (Up/Down) | Zoom In | Zoom Out | Dolly In | Dolly Out | Tracking/Follow | Crane/Jib | Handheld | Steadicam

# Subject Types
speaker | audience | product_demo | venue_exterior | venue_interior | signage_branding | networking | B-roll | title_card | transition_graphic

# Editorial Purpose
establish_context | introduce_speaker | build_energy | deliver_information | show_reaction | emotional_beat | transition | pacing_break | closing

# Output JSON Schema
{{
  "total_duration": "MM:SS",
  "scenes": [
    {{
      "index": 1,
      "start": "MM:SS",
      "end": "MM:SS",
      "duration_sec": 3.0,
      "shot_type": "Medium Shot",
      "camera_movement": "Static",
      "subject_type": "speaker",
      "editorial_purpose": "introduce_speaker",
      "description": "ë°œí‘œìê°€ ë¬´ëŒ€ ì¤‘ì•™ì—ì„œ ì¸ì‚¬í•˜ë©° ë°œí‘œë¥¼ ì‹œì‘"
    }}
  ],
  "editing_patterns": {{
    "avg_cut_duration_sec": 2.5,
    "pacing_curve": "slow_start â†’ fast_middle â†’ slow_end",
    "shot_type_distribution": {{
      "Wide Shot": 15,
      "Medium Shot": 40,
      "Close-up": 30,
      "Other": 15
    }},
    "recurring_sequences": [
      "Wide â†’ Medium â†’ Close-up íŒ¨í„´ì´ ë°œí‘œ ì„¹ì…˜ì—ì„œ ë°˜ë³µ"
    ],
    "dominant_camera_style": "Static with occasional slow pan"
  }},
  "narrative_structure": "ë„ì…(í–‰ì‚¬ì¥ ì „ê²½) â†’ ì „ê°œ(ë°œí‘œ í•˜ì´ë¼ì´íŠ¸) â†’ í´ë¼ì´ë§¥ìŠ¤(ê´€ê° ë°˜ì‘) â†’ ë§ˆë¬´ë¦¬(ë„¤íŠ¸ì›Œí‚¹)",
  "summary": "ì „ì²´ í¸ì§‘ ìŠ¤íƒ€ì¼ ìš”ì•½ (í†¤, ì†ë„ê°, íŠ¹ì§•ì  ê¸°ë²• ë“±)"
}}

Return ONLY valid JSON. No markdown fences, no extra text.
"""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í•µì‹¬ í•¨ìˆ˜ë“¤
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def download_video(url: str, output_dir: str) -> tuple[str, dict]:
    """YouTube ì˜ìƒ ë‹¤ìš´ë¡œë“œ. (íŒŒì¼ ê²½ë¡œ, ë©”íƒ€ë°ì´í„°) ë°˜í™˜."""
    ydl_opts = {
        "format": "best[height<=720]",
        "outtmpl": os.path.join(output_dir, "%(title)s.%(ext)s"),
        "quiet": True,
        "no_warnings": True,
    }
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        info = ydl.extract_info(url, download=True)
        filename = ydl.prepare_filename(info)
        metadata = {
            "title": info.get("title", ""),
            "duration": info.get("duration", 0),
            "uploader": info.get("uploader", ""),
            "upload_date": info.get("upload_date", ""),
            "url": url,
        }
        return filename, metadata


def detect_scene_changes(video_path: str, threshold: float = 0.3) -> list[float]:
    """FFmpegë¡œ ì”¬ ì²´ì¸ì§€(í¸ì§‘ì ) íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ."""
    cmd = [
        FFMPEG_PATH,
        "-i", video_path,
        "-filter:v", f"select='gt(scene,{threshold})',showinfo",
        "-f", "null",
        "-",
    ]
    try:
        result = subprocess.run(
            cmd, capture_output=True, timeout=300, encoding="utf-8", errors="replace"
        )
        stderr = result.stderr or ""
    except FileNotFoundError:
        st.warning("FFmpegê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ì”¬ ì²´ì¸ì§€ ê°ì§€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return []
    except subprocess.TimeoutExpired:
        st.warning("FFmpeg ì²˜ë¦¬ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return []
    except Exception as e:
        st.warning(f"FFmpeg ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        return []

    # showinfo ì¶œë ¥ì—ì„œ pts_time íŒŒì‹±
    timestamps = []
    pattern = re.compile(r"pts_time:(\d+\.?\d*)")
    for line in stderr.split("\n"):
        if "showinfo" in line:
            match = pattern.search(line)
            if match:
                timestamps.append(round(float(match.group(1)), 1))

    return sorted(set(timestamps))


def format_timestamps_for_prompt(timestamps: list[float], total_duration: float) -> str:
    """íƒ€ì„ìŠ¤íƒ¬í”„ ëª©ë¡ì„ í”„ë¡¬í”„íŠ¸ì— ë„£ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜."""
    if not timestamps:
        return "No cuts detected."

    lines = []
    # ì²« ì„¸ê·¸ë¨¼íŠ¸
    prev = 0.0
    for i, ts in enumerate(timestamps):
        dur = round(ts - prev, 1)
        lines.append(f"  Segment {i+1}: {prev:.1f}s â†’ {ts:.1f}s  (duration: {dur:.1f}s)")
        prev = ts
    # ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸
    dur = round(total_duration - prev, 1)
    lines.append(f"  Segment {len(timestamps)+1}: {prev:.1f}s â†’ {total_duration:.1f}s  (duration: {dur:.1f}s)")

    return "\n".join(lines)


def get_video_duration(video_path: str) -> float:
    """FFprobeë¡œ ì˜ìƒ ê¸¸ì´(ì´ˆ) êµ¬í•˜ê¸°."""
    cmd = [
        FFPROBE_PATH,
        "-v", "error",
        "-show_entries", "format=duration",
        "-of", "default=noprint_wrappers=1:nokey=1",
        video_path,
    ]
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
        return float(result.stdout.strip())
    except Exception:
        return 0.0


def upload_to_gemini(file_path: str):
    """Geminiì— íŒŒì¼ ì—…ë¡œë“œ í›„ ì²˜ë¦¬ ì™„ë£Œê¹Œì§€ ëŒ€ê¸°."""
    file = genai.upload_file(file_path)

    max_wait = 300  # ìµœëŒ€ 5ë¶„ ëŒ€ê¸°
    elapsed = 0
    while file.state.name == "PROCESSING":
        time.sleep(3)
        elapsed += 3
        if elapsed > max_wait:
            raise TimeoutError("Gemini íŒŒì¼ ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼ (5ë¶„)")
        file = genai.get_file(file.name)

    if file.state.name == "FAILED":
        raise ValueError(f"Gemini íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {file.state.name}")

    return file


def analyze_video(
    gemini_file,
    model_name: str,
    scene_timestamps: list[float] | None = None,
    total_duration: float = 0.0,
) -> str:
    """Geminië¡œ ì˜ìƒ ë¶„ì„ ìˆ˜í–‰."""
    model = genai.GenerativeModel(model_name)

    if scene_timestamps:
        prompt = PROMPT_WITH_SCENE_DATA.format(
            scene_timestamps=format_timestamps_for_prompt(scene_timestamps, total_duration),
            cut_count=len(scene_timestamps),
        )
    else:
        prompt = PROMPT_WITHOUT_SCENE_DATA

    response = model.generate_content(
        [gemini_file, prompt],
        generation_config={
            "temperature": 0.2,
            "response_mime_type": "application/json",
            "max_output_tokens": 65536,
        },
    )
    return response.text


def parse_json_response(text: str) -> dict:
    """ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ (ë°©ì–´ì  íŒŒì‹±)."""
    cleaned = text.strip()

    # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ íœìŠ¤ ì œê±°
    if cleaned.startswith("```"):
        # ```json ë˜ëŠ” ``` ì œê±°
        first_newline = cleaned.find("\n")
        cleaned = cleaned[first_newline + 1 :]
        if cleaned.endswith("```"):
            cleaned = cleaned[:-3]
        cleaned = cleaned.strip()

    try:
        return json.loads(cleaned)
    except json.JSONDecodeError:
        # ë¶€ë¶„ JSONì´ë¼ë„ ì°¾ì•„ë³´ê¸°
        brace_start = cleaned.find("{")
        brace_end = cleaned.rfind("}")
        if brace_start != -1 and brace_end != -1:
            try:
                return json.loads(cleaned[brace_start : brace_end + 1])
            except json.JSONDecodeError:
                pass
        return {"raw_response": text}


def enrich_with_metadata(result: dict, metadata: dict, scene_timestamps: list[float] | None) -> dict:
    """ë¶„ì„ ê²°ê³¼ì— ë©”íƒ€ë°ì´í„°ì™€ ì”¬ ì²´ì¸ì§€ ì •ë³´ë¥¼ ì¶”ê°€."""
    result["_metadata"] = {
        "video_title": metadata.get("title", ""),
        "video_url": metadata.get("url", ""),
        "video_duration_sec": metadata.get("duration", 0),
        "uploader": metadata.get("uploader", ""),
        "upload_date": metadata.get("upload_date", ""),
        "analyzed_at": datetime.now().isoformat(),
        "model_used": selected_model,
    }
    if scene_timestamps is not None:
        result["_metadata"]["ffmpeg_scene_changes"] = scene_timestamps
        result["_metadata"]["ffmpeg_cut_count"] = len(scene_timestamps)
    return result


def save_analysis_result(video_name: str, result_json: dict, save_dir: Path) -> tuple[Path, Path]:
    """ë¶„ì„ ê²°ê³¼ë¥¼ JSON + Markdown íŒŒì¼ë¡œ ì €ì¥."""
    safe_name = Path(video_name).stem
    safe_name = "".join(c if c.isalnum() or c in (" ", "-", "_") else "_" for c in safe_name)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    json_filename = f"{safe_name}_{timestamp}.json"
    json_path = save_dir / json_filename
    json_path.write_text(json.dumps(result_json, ensure_ascii=False, indent=2), encoding="utf-8")

    md_filename = f"{safe_name}_{timestamp}.md"
    md_path = save_dir / md_filename
    md_path.write_text(json_to_markdown(result_json), encoding="utf-8")

    return md_path, json_path


def get_analyzed_urls(output_dir: Path) -> set[str]:
    """output í´ë”ì˜ JSON íŒŒì¼ì—ì„œ ì´ë¯¸ ë¶„ì„ëœ video_url ì…‹ ë°˜í™˜."""
    urls = set()
    for json_file in output_dir.glob("*.json"):
        try:
            data = json.loads(json_file.read_text(encoding="utf-8"))
            url = data.get("_metadata", {}).get("video_url", "")
            if url:
                urls.add(url)
        except Exception:
            continue
    return urls


def search_youtube(keyword: str, max_results: int, min_duration: int, max_duration: int) -> list[dict]:
    """yt-dlpë¡œ YouTube ê²€ìƒ‰, í•„í„°ë§ëœ URL+ë©”íƒ€ë°ì´í„° ë¦¬ìŠ¤íŠ¸ ë°˜í™˜."""
    ydl_opts = {
        "quiet": True,
        "no_warnings": True,
        "extract_flat": False,
        "skip_download": True,
        "ignoreerrors": True,
    }
    search_query = f"ytsearch{max_results * 3}:{keyword}"

    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        result = ydl.extract_info(search_query, download=False)

    entries = result.get("entries", []) if result else []
    filtered = []
    for entry in entries:
        if not entry:
            continue
        duration = entry.get("duration") or 0
        if min_duration <= duration <= max_duration:
            filtered.append({
                "url": entry.get("webpage_url") or f"https://www.youtube.com/watch?v={entry.get('id', '')}",
                "title": entry.get("title", "ì œëª© ì—†ìŒ"),
                "duration": duration,
                "uploader": entry.get("uploader", ""),
                "upload_date": entry.get("upload_date", ""),
            })

    return filtered


def run_batch_analysis(
    videos: list[dict],
    model_name: str,
    use_scene: bool,
    threshold: float,
    auto_save: bool,
    save_dir: Path,
    progress_bar,
    status_text,
) -> list[dict]:
    """ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜ë“¤ì„ ë£¨í”„ë¡œ í˜¸ì¶œ, ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜."""
    results = []
    total = len(videos)

    for i, video_info in enumerate(videos):
        url = video_info["url"]
        title = video_info["title"]
        status_text.write(f"**[{i + 1}/{total}]** {title}")
        progress_bar.progress((i) / total, text=f"ë¶„ì„ ì¤‘: {i + 1}/{total}")

        try:
            with tempfile.TemporaryDirectory() as temp_dir:
                # ë‹¤ìš´ë¡œë“œ
                video_path, metadata = download_video(url, temp_dir)
                video_name = Path(video_path).name

                # FFmpeg ì”¬ ì²´ì¸ì§€
                scene_timestamps = None
                total_duration = get_video_duration(video_path) or metadata.get("duration", 0)

                if use_scene:
                    scene_timestamps = detect_scene_changes(video_path, threshold)
                    if not scene_timestamps:
                        scene_timestamps = None

                # Gemini ì—…ë¡œë“œ + ë¶„ì„
                uploaded_file = upload_to_gemini(video_path)
                result_text = analyze_video(
                    uploaded_file, model_name,
                    scene_timestamps=scene_timestamps,
                    total_duration=total_duration,
                )

                # íŒŒì‹± & ë©”íƒ€ë°ì´í„°
                result_json = parse_json_response(result_text)
                result_json = enrich_with_metadata(result_json, metadata, scene_timestamps)

            # ì €ì¥
            if auto_save:
                save_analysis_result(video_name, result_json, save_dir)

            results.append({"status": "success", "title": title, "url": url, "data": result_json})

        except Exception as e:
            results.append({"status": "fail", "title": title, "url": url, "error": str(e)})

    progress_bar.progress(1.0, text="ì™„ë£Œ!")
    return results


def merge_results_for_training(results: list[dict]) -> str:
    """ê°œë³„ JSONì„ LLM í•™ìŠµìš© í†µí•© JSONLë¡œ ë³‘í•©."""
    lines = []
    for r in results:
        if r["status"] != "success":
            continue
        data = r["data"]
        training_record = {
            "video_url": data.get("_metadata", {}).get("video_url", ""),
            "video_title": data.get("_metadata", {}).get("video_title", ""),
            "total_duration": data.get("total_duration", ""),
            "scenes": data.get("scenes", []),
            "editing_patterns": data.get("editing_patterns", {}),
            "narrative_structure": data.get("narrative_structure", ""),
            "summary": data.get("summary", ""),
        }
        lines.append(json.dumps(training_record, ensure_ascii=False))
    return "\n".join(lines)


def json_to_markdown(data: dict) -> str:
    """JSON ë¶„ì„ ê²°ê³¼ë¥¼ ì‚¬ëŒì´ ì½ê¸° ì¢‹ì€ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜."""
    md = ["# ğŸ¬ ì˜ìƒ í¸ì§‘ ë¶„ì„ ë¦¬í¬íŠ¸\n"]
    handled = set()

    # ë©”íƒ€ë°ì´í„°
    meta = data.get("_metadata", {})
    if meta:
        handled.add("_metadata")
        md.append(f"**ì˜ìƒ:** {meta.get('video_title', '-')}")
        md.append(f"**URL:** {meta.get('video_url', '-')}")
        md.append(f"**ë¶„ì„ ëª¨ë¸:** {meta.get('model_used', '-')}")
        md.append(f"**ë¶„ì„ ì¼ì‹œ:** {meta.get('analyzed_at', '-')}")
        if meta.get("ffmpeg_cut_count") is not None:
            md.append(f"**FFmpeg ê°ì§€ ì»· ìˆ˜:** {meta['ffmpeg_cut_count']}")
        md.append("")

    # ì˜ìƒ ê¸¸ì´
    if "total_duration" in data:
        md.append(f"## ğŸ“ ì˜ìƒ ê¸¸ì´: {data['total_duration']}\n")
        handled.add("total_duration")

    # ë‚´ëŸ¬í‹°ë¸Œ êµ¬ì¡°
    if "narrative_structure" in data:
        md.append(f"## ğŸ“– ë‚´ëŸ¬í‹°ë¸Œ êµ¬ì¡°\n{data['narrative_structure']}\n")
        handled.add("narrative_structure")

    # ì”¬ ë¶„ì„
    if "scenes" in data:
        handled.add("scenes")
        md.append("## ğŸï¸ ì”¬ë³„ ë¶„ì„\n")

        scene_fields = {
            "shot_type": "ìƒ· íƒ€ì…",
            "camera_movement": "ì¹´ë©”ë¼",
            "subject_type": "í”¼ì‚¬ì²´",
            "editorial_purpose": "í¸ì§‘ ì˜ë„",
            "description": "ì„¤ëª…",
        }
        skip_keys = {"index", "start", "end", "duration_sec"}

        for i, scene in enumerate(data["scenes"]):
            idx = scene.get("index", i + 1)
            start = scene.get("start", "?")
            end = scene.get("end", "?")
            dur = scene.get("duration_sec", "")
            dur_str = f" ({dur}s)" if dur else ""
            md.append(f"### #{idx} | {start} â†’ {end}{dur_str}\n")

            for key, label in scene_fields.items():
                val = scene.get(key)
                if val is not None:
                    md.append(f"- **{label}:** {val}")

            # ìŠ¤í‚¤ë§ˆì— ì—†ëŠ” ì¶”ê°€ í•„ë“œë„ ì¶œë ¥
            extra = [k for k in scene if k not in scene_fields and k not in skip_keys]
            for key in extra:
                val = scene[key]
                if val is not None:
                    md.append(f"- **{key}:** {val}")

            md.append("")

    # í¸ì§‘ íŒ¨í„´
    if "editing_patterns" in data:
        handled.add("editing_patterns")
        ep = data["editing_patterns"]
        md.append("## ğŸ“Š í¸ì§‘ íŒ¨í„´\n")
        if "avg_cut_duration_sec" in ep:
            md.append(f"- **í‰ê·  ì»· ê¸¸ì´:** {ep['avg_cut_duration_sec']}ì´ˆ")
        if "pacing_curve" in ep:
            md.append(f"- **í˜ì´ì‹± ê³¡ì„ :** {ep['pacing_curve']}")
        if "dominant_camera_style" in ep:
            md.append(f"- **ì£¼ìš” ì¹´ë©”ë¼ ìŠ¤íƒ€ì¼:** {ep['dominant_camera_style']}")
        if "shot_type_distribution" in ep:
            md.append("- **ìƒ· íƒ€ì… ë¶„í¬:**")
            for shot, pct in ep["shot_type_distribution"].items():
                md.append(f"  - {shot}: {pct}%")
        if "recurring_sequences" in ep:
            md.append("- **ë°˜ë³µ íŒ¨í„´:**")
            for seq in ep["recurring_sequences"]:
                md.append(f"  - {seq}")
        md.append("")

    # ìš”ì•½
    if "summary" in data:
        md.append(f"## ğŸ“ í¸ì§‘ ìŠ¤íƒ€ì¼ ìš”ì•½\n{data['summary']}\n")
        handled.add("summary")

    # raw_response (íŒŒì‹± ì‹¤íŒ¨ ì‹œ)
    if "raw_response" in data:
        md.append(f"## âš ï¸ ì›ë³¸ ì‘ë‹µ\n```\n{data['raw_response']}\n```\n")
        handled.add("raw_response")

    # ë‚˜ë¨¸ì§€ í‚¤
    for key in data:
        if key not in handled:
            val = data[key]
            if isinstance(val, (dict, list)):
                md.append(f"## {key}\n```json\n{json.dumps(val, ensure_ascii=False, indent=2)}\n```\n")
            else:
                md.append(f"## {key}\n{val}\n")

    return "\n".join(md)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸ UI (íƒ­ êµ¬ì¡°)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

tab_single, tab_batch = st.tabs(["ë‹¨ì¼ ë¶„ì„", "ë°°ì¹˜ ìˆ˜ì§‘"])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë‹¨ì¼ ë¶„ì„ íƒ­
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab_single:
    url_input = st.text_area(
        "YouTube URL ì…ë ¥",
        placeholder="https://youtube.com/watch?v=xxxxx\nì—¬ëŸ¬ ê°œ ì…ë ¥ ì‹œ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„",
        height=100,
    )

    col_btn, _ = st.columns([1, 4])
    with col_btn:
        analyze_btn = st.button("ğŸ” ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True)

    if analyze_btn:
        if not api_key:
            st.error("ì‚¬ì´ë“œë°”ì—ì„œ Gemini API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif not url_input.strip():
            st.error("YouTube URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            urls = [u.strip() for u in url_input.strip().split("\n") if u.strip()]

            for i, url in enumerate(urls):
                st.divider()
                st.subheader(f"ì˜ìƒ {i + 1}/{len(urls)}")

                with st.status("ë¶„ì„ ì¤‘...", expanded=True) as status:
                    try:
                        with tempfile.TemporaryDirectory() as temp_dir:
                            # Step 1: ë‹¤ìš´ë¡œë“œ
                            st.write("ğŸ“¥ ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì¤‘...")
                            video_path, metadata = download_video(url, temp_dir)
                            video_name = Path(video_path).name
                            st.write(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: **{metadata.get('title', video_name)}**")

                            # Step 2: FFmpeg ì”¬ ì²´ì¸ì§€ ê°ì§€ (ì„ íƒ)
                            scene_timestamps = None
                            total_duration = get_video_duration(video_path) or metadata.get("duration", 0)

                            if use_scene_detection:
                                st.write(f"ğŸ” FFmpeg ì”¬ ì²´ì¸ì§€ ê°ì§€ ì¤‘ (ê°ë„: {scene_threshold})...")
                                scene_timestamps = detect_scene_changes(video_path, scene_threshold)
                                if scene_timestamps:
                                    st.write(f"âœ… **{len(scene_timestamps)}ê°œ** í¸ì§‘ì  ê°ì§€ë¨")
                                    with st.expander("ê°ì§€ëœ í¸ì§‘ì  íƒ€ì„ìŠ¤íƒ¬í”„"):
                                        st.code(
                                            format_timestamps_for_prompt(scene_timestamps, total_duration),
                                            language="text",
                                        )
                                else:
                                    st.write("âš ï¸ í¸ì§‘ì ì„ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. Gemini ë‹¨ë… ë¶„ì„ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
                                    scene_timestamps = None

                            # Step 3: Gemini ì—…ë¡œë“œ
                            st.write("â˜ï¸ Geminiì— ì—…ë¡œë“œ ì¤‘...")
                            uploaded_file = upload_to_gemini(video_path)
                            st.write("âœ… ì—…ë¡œë“œ ì™„ë£Œ")

                            # Step 4: AI ë¶„ì„
                            pipeline_mode = "2ë‹¨ê³„ (FFmpeg + Gemini)" if scene_timestamps else "Gemini ë‹¨ë…"
                            st.write(f"ğŸ¤– AI ë¶„ì„ ì¤‘... [{pipeline_mode}]")
                            result_text = analyze_video(
                                uploaded_file,
                                selected_model,
                                scene_timestamps=scene_timestamps,
                                total_duration=total_duration,
                            )
                            st.write("âœ… ë¶„ì„ ì™„ë£Œ")

                            # Step 5: íŒŒì‹± & ë©”íƒ€ë°ì´í„° ì¶”ê°€
                            result_json = parse_json_response(result_text)
                            result_json = enrich_with_metadata(result_json, metadata, scene_timestamps)

                        status.update(label="âœ… ë¶„ì„ ì™„ë£Œ!", state="complete")

                        # Step 6: ìë™ ì €ì¥
                        if auto_save:
                            md_path, json_path = save_analysis_result(video_name, result_json, save_dir)
                            st.success(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: `{json_path.name}` / `{md_path.name}`")

                        # Step 7: ê²°ê³¼ í‘œì‹œ
                        if output_format == "JSON":
                            st.json(result_json)
                        else:
                            st.markdown(json_to_markdown(result_json))

                        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                        dl_col1, dl_col2 = st.columns(2)
                        with dl_col1:
                            st.download_button(
                                "ğŸ“„ JSON ë‹¤ìš´ë¡œë“œ",
                                json.dumps(result_json, ensure_ascii=False, indent=2),
                                file_name=f"{Path(video_name).stem}_analysis.json",
                                mime="application/json",
                            )
                        with dl_col2:
                            st.download_button(
                                "ğŸ“ Markdown ë‹¤ìš´ë¡œë“œ",
                                json_to_markdown(result_json),
                                file_name=f"{Path(video_name).stem}_analysis.md",
                                mime="text/markdown",
                            )

                    except Exception as e:
                        status.update(label="âŒ ì˜¤ë¥˜ ë°œìƒ", state="error")
                        st.error(f"ì˜¤ë¥˜: {str(e)}")
                        st.exception(e)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë°°ì¹˜ ìˆ˜ì§‘ íƒ­
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab_batch:
    st.subheader("í‚¤ì›Œë“œë¡œ YouTube ì˜ìƒ ê²€ìƒ‰ & ì¼ê´„ ë¶„ì„")
    st.markdown("ê²€ìƒ‰ í‚¤ì›Œë“œë¡œ ì˜ìƒì„ ìë™ ìˆ˜ì§‘í•˜ê³ , ìˆœì°¨ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ LLM í•™ìŠµ ë°ì´í„°ë¥¼ ëŒ€ëŸ‰ êµ¬ì¶•í•©ë‹ˆë‹¤.")

    # ê²€ìƒ‰ ì„¤ì •
    batch_keyword = st.text_input(
        "ê²€ìƒ‰ í‚¤ì›Œë“œ",
        placeholder='ì˜ˆ: "í–‰ì‚¬ ìŠ¤ì¼€ì¹˜ ì˜ìƒ", "startup event highlight"',
    )

    col_count, col_min, col_max = st.columns(3)
    with col_count:
        batch_max_results = st.slider("ìµœëŒ€ ìˆ˜ì§‘ ê°œìˆ˜", min_value=1, max_value=50, value=10)
    with col_min:
        batch_min_duration = st.number_input("ìµœì†Œ ì˜ìƒ ê¸¸ì´ (ë¶„)", min_value=0, max_value=120, value=1, step=1)
    with col_max:
        batch_max_duration = st.number_input("ìµœëŒ€ ì˜ìƒ ê¸¸ì´ (ë¶„)", min_value=1, max_value=120, value=10, step=1)

    col_search, _ = st.columns([1, 4])
    with col_search:
        search_btn = st.button("ğŸ” ê²€ìƒ‰", type="primary", use_container_width=True)

    # ê²€ìƒ‰ ì‹¤í–‰ â†’ ì„¸ì…˜ì— selected / reserve ë¶„ë¦¬ ì €ì¥
    if search_btn:
        if not batch_keyword.strip():
            st.error("ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("YouTube ê²€ìƒ‰ ì¤‘..."):
                try:
                    all_candidates = search_youtube(
                        batch_keyword.strip(),
                        batch_max_results,
                        int(batch_min_duration * 60),
                        int(batch_max_duration * 60),
                    )
                    analyzed = get_analyzed_urls(save_dir)
                    excluded = st.session_state.get("batch_excluded_urls", set())
                    all_candidates = [v for v in all_candidates if v["url"] not in analyzed and v["url"] not in excluded]
                    st.session_state["batch_selected"] = all_candidates[:batch_max_results]
                    st.session_state["batch_reserve"] = all_candidates[batch_max_results:]
                    st.session_state["batch_keyword"] = batch_keyword.strip()
                except Exception as e:
                    st.error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                    st.session_state["batch_selected"] = []
                    st.session_state["batch_reserve"] = []

    # ê²€ìƒ‰ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
    if st.session_state.get("batch_selected"):
        selected = st.session_state["batch_selected"]
        reserve = st.session_state.get("batch_reserve", [])
        st.success(
            f"'{st.session_state.get('batch_keyword', '')}' â€” "
            f"ì„ íƒ: **{len(selected)}ê°œ** Â· ëŒ€ê¸°: {len(reserve)}ê°œ"
        )

        # ì˜ìƒ ëª©ë¡ + ë¹¼ê¸° ë²„íŠ¼
        for idx, v in enumerate(selected):
            dur_min = v["duration"] // 60
            dur_sec = v["duration"] % 60
            col_info, col_btn_rm = st.columns([5, 1])
            with col_info:
                st.markdown(
                    f"**{idx + 1}.** {v['title']}  \n"
                    f"  ê¸¸ì´: {dur_min}:{dur_sec:02d} Â· {v['uploader']}  \n"
                    f"  `{v['url']}`"
                )
            with col_btn_rm:
                if st.button("ë¹¼ê¸°", key=f"remove_{idx}"):
                    removed = st.session_state["batch_selected"].pop(idx)
                    if "batch_excluded_urls" not in st.session_state:
                        st.session_state["batch_excluded_urls"] = set()
                    st.session_state["batch_excluded_urls"].add(removed["url"])
                    if st.session_state.get("batch_reserve"):
                        st.session_state["batch_selected"].append(
                            st.session_state["batch_reserve"].pop(0)
                        )
                    st.rerun()

        st.divider()

        col_start, _ = st.columns([1, 4])
        with col_start:
            batch_start_btn = st.button(
                f"ğŸš€ {len(selected)}ê°œ ì˜ìƒ ë¶„ì„ ì‹œì‘",
                type="primary",
                use_container_width=True,
            )

        if batch_start_btn:
            if not api_key:
                st.error("ì‚¬ì´ë“œë°”ì—ì„œ Gemini API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                st.divider()
                progress_bar = st.progress(0, text="ì¤€ë¹„ ì¤‘...")
                status_text = st.empty()

                batch_results = run_batch_analysis(
                    videos=selected,
                    model_name=selected_model,
                    use_scene=use_scene_detection,
                    threshold=scene_threshold,
                    auto_save=auto_save,
                    save_dir=save_dir,
                    progress_bar=progress_bar,
                    status_text=status_text,
                )

                # ìš”ì•½ ë¦¬í¬íŠ¸
                success_count = sum(1 for r in batch_results if r["status"] == "success")
                fail_count = sum(1 for r in batch_results if r["status"] == "fail")

                st.divider()
                st.subheader("ë°°ì¹˜ ë¶„ì„ ê²°ê³¼ ìš”ì•½")

                col_s, col_f = st.columns(2)
                with col_s:
                    st.metric("ì„±ê³µ", f"{success_count}ê°œ")
                with col_f:
                    st.metric("ì‹¤íŒ¨", f"{fail_count}ê°œ")

                # ê°œë³„ ê²°ê³¼ í‘œì‹œ
                for r in batch_results:
                    if r["status"] == "success":
                        with st.expander(f"âœ… {r['title']}"):
                            st.json(r["data"])
                    else:
                        with st.expander(f"âŒ {r['title']}"):
                            st.error(r["error"])

                # í†µí•© JSONL ë‹¤ìš´ë¡œë“œ
                if success_count > 0:
                    st.divider()
                    jsonl_data = merge_results_for_training(batch_results)
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

                    # JSONL íŒŒì¼ ìë™ ì €ì¥
                    if auto_save:
                        safe_kw = "".join(
                            c if c.isalnum() or c in (" ", "-", "_") else "_"
                            for c in st.session_state.get("batch_keyword", "batch")
                        )
                        jsonl_path = save_dir / f"batch_{safe_kw}_{timestamp}.jsonl"
                        jsonl_path.write_text(jsonl_data, encoding="utf-8")
                        st.success(f"ğŸ’¾ í†µí•© JSONL ì €ì¥ ì™„ë£Œ: `{jsonl_path.name}`")

                    st.download_button(
                        "ğŸ“¦ í†µí•© í•™ìŠµ ë°ì´í„° (JSONL) ë‹¤ìš´ë¡œë“œ",
                        jsonl_data,
                        file_name=f"training_data_{timestamp}.jsonl",
                        mime="application/jsonl",
                    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í‘¸í„°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.divider()
st.caption("Powered by Google Gemini API Â· FFmpeg Â· yt-dlp")
